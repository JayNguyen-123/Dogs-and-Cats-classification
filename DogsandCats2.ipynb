{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMtb0LDfLzeMHRur4SWRREX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JayNguyen-123/Dogs-and-Cats-classification/blob/main/DogsandCats2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fSxtTlcKI6gD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 989
        },
        "outputId": "57fbdc94-2773-44eb-d5d0-d2ee35a3410b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 445 validated image filenames belonging to 1 classes.\n",
            "Found 112 validated image filenames belonging to 1 classes.\n",
            "Found 0 validated image filenames belonging to 0 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/legacy/preprocessing/image.py:920: UserWarning: Found 445 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.5768 - loss: 1.4385 - val_accuracy: 1.0000 - val_loss: 2.1567e-04 - learning_rate: 0.0010\n",
            "Epoch 2/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/callbacks/callback_list.py:96: UserWarning: Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: accuracy,loss,val_accuracy,val_loss,learning_rate.\n",
            "  callback.on_epoch_end(epoch, logs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8667 - loss: 0.3883 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 0.0010\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1s/step - accuracy: 0.7561 - loss: 0.5213 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.8667 - loss: 0.3031 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 1s/step - accuracy: 0.9448 - loss: 0.2244 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9333 - loss: 0.1318 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 973ms/step - accuracy: 0.9574 - loss: 0.1379 - val_accuracy: 1.0000 - val_loss: 1.7688e-06 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0694 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 0.9887 - loss: 0.0532 - val_accuracy: 1.0000 - val_loss: 1.5895e-08 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0129 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 0.0010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Must provide at least one structure",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-c41e90228379>\u001b[0m in \u001b[0;36m<cell line: 125>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0mnb_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_samples\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/tree/optree_impl.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structures)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"`func` must be callable. Received: func={func}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstructures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Must provide at least one structure\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mother\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstructures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0massert_same_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Must provide at least one structure"
          ]
        }
      ],
      "source": [
        "# Import libraries for model\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import os\n",
        "\n",
        "# Define image properties\n",
        "\n",
        "img_width = 128\n",
        "img_height = 128\n",
        "img_size = (img_width, img_height)\n",
        "img_channels = 3\n",
        "\n",
        "# Prepare data set for training\n",
        "filenames = os.listdir('/content/sample_data/train')\n",
        "\n",
        "categories = []\n",
        "for f in filenames:\n",
        "    category = f.split('.')[0]\n",
        "    if category == 'dog:':\n",
        "        categories.append(1)\n",
        "    else:\n",
        "        categories.append(0)\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'filename': filenames,\n",
        "    'category': categories\n",
        "})\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, BatchNormalization, Dropout, MaxPooling2D, Flatten\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(img_width, img_height, img_channels)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# Define callbacks and learning rate\n",
        "\n",
        "earlystop = EarlyStopping(patience=10)\n",
        "learning_rate_redution = ReduceLROnPlateau(monitor='val_acc', patience=2, verbose=1, factor=0.5, min_lr=0.00001)\n",
        "callbacks = [earlystop, learning_rate_redution]\n",
        "\n",
        "# Manage data\n",
        "\n",
        "df['category'] = df['category'].replace({0: 'cat', 1: 'dog'})\n",
        "train_df, validate_df = train_test_split(df, test_size=0.20, random_state=42)\n",
        "\n",
        "train_df = train_df.reset_index(drop=True)\n",
        "validate_df = validate_df.reset_index(drop=True)\n",
        "\n",
        "total_train = train_df.shape[0]\n",
        "total_validate = validate_df.shape[0]\n",
        "batch_size = 15\n",
        "\n",
        "train_datagen = ImageDataGenerator(rotation_range=15,\n",
        "                                   rescale=1. / 255,\n",
        "                                   shear_range=0.1,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True,\n",
        "                                   width_shift_range=0.1,\n",
        "                                   height_shift_range=0.1)\n",
        "train_generator = train_datagen.flow_from_dataframe(train_df, '/content/sample_data/train',\n",
        "                                                    x_col='filename', y_col='category',\n",
        "                                                    target_size=img_size,\n",
        "                                                    class_mode='categorical',\n",
        "                                                    batch_size=batch_size)\n",
        "validation_dategen = ImageDataGenerator(rescale=1. / 255)\n",
        "validation_generator = validation_dategen.flow_from_dataframe(validate_df,\n",
        "                                                              '/content/sample_data/train',\n",
        "                                                              x_col='filename',\n",
        "                                                              y_col='category',\n",
        "                                                              target_size=img_size,\n",
        "                                                              class_mode='categorical',\n",
        "                                                              batch_size=batch_size\n",
        "                                                              )\n",
        "\n",
        "test_datagen = ImageDataGenerator(rotation_range=15,\n",
        "                                  rescale=1. / 255,\n",
        "                                  shear_range=0.1,\n",
        "                                  zoom_range=0.2,\n",
        "                                  horizontal_flip=True,\n",
        "                                  width_shift_range=0.1,\n",
        "                                  height_shift_range=0.1)\n",
        "\n",
        "test_generator = test_datagen.flow_from_dataframe(train_df, '/content/sample_data/test',\n",
        "                                                  x_col='filename',\n",
        "                                                  y_col='category',\n",
        "                                                  target_size=img_size,\n",
        "                                                  class_mode='categorical',\n",
        "                                                  batch_size=batch_size)\n",
        "\n",
        "# Train the model\n",
        "epochs = 10\n",
        "hist = model.fit(train_generator, epochs=epochs, validation_data=validation_generator,\n",
        "                 validation_steps=total_validate // batch_size,\n",
        "                 steps_per_epoch=total_train // batch_size,\n",
        "                 callbacks=callbacks)\n",
        "\n",
        "model.save('CatAndDog.h5')\n",
        "\n",
        "#Test data prep\n",
        "test_file = os.listdir('/content/sample_data/test')\n",
        "test_df = pd.DataFrame({\n",
        "    'filename': test_file\n",
        "})\n",
        "\n",
        "nb_samples = test_df.shape[0]\n",
        "\n",
        "# make prediction in test samples\n",
        "predict = model.predict(test_generator, steps=np.ceil(nb_samples/batch_size))\n",
        "\n",
        "#Convert labels to categories\n",
        "\n",
        "test_df['category'] = np.argmax(predict, axis=-1)\n",
        "label_map = dict((v,k) for k,v in train_generator.class_indices.items())\n",
        "test_df['category'] = test_df['category'].replace(label_map)\n",
        "test_df['category'] = test_df['category'].replace({ 'dog': 1, 'cat': 0 })\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tkinter as tk\n",
        "from tkinter import filedialog\n",
        "from tkinter import *\n",
        "from PIL import ImageTk, Image\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model('CatAndDog.h5')\n",
        "\n",
        "classes  = {\n",
        "     0: 'It is a cat',\n",
        "     1: 'It is a dog'\n",
        " }\n",
        "\n",
        "top = tk.Tk()\n",
        "top.geometry('800x600')\n",
        "top.title('CatsVsDogs CLassification')\n",
        "top.configure(background='#CDCDCD')\n",
        "label = Label(top, background='#CDCDCD', font=('arial', 15, 'bold'))\n",
        "sign_img = Label(top)\n",
        "\n",
        "def classify(file_path):\n",
        "\n",
        "    global label_packed\n",
        "    img = Image.open(file_path)\n",
        "    img = img.resize((128,128))\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    img = np.array(img)\n",
        "    img = img/255\n",
        "    pred = model.predict([img])[0]\n",
        "    sign = classes[pred]\n",
        "    print(sign)\n",
        "    label.configure(foreground='#011638', text=sign)\n",
        "\n",
        "def show_classify_button(file_path):\n",
        "    classify_b = Button(top, text=\"Classify Image\", command=lambda: classify(file_path),\n",
        "                        padx=10, pady=5)\n",
        "    classify_b.configure(background='#364156', foreground='white',\n",
        "                         font=('arial', 10, 'bold'))\n",
        "    classify_b.place(relx=0.79, rely=0.46)\n",
        "\n",
        "def upload_image():\n",
        "    try:\n",
        "        file_path = filedialog.askopenfilename()\n",
        "        uploaded = Image.open(file_path)\n",
        "        uploaded.thumbnail(((top.winfo_width()/2.25),\n",
        "                            (top.winfo_height()/2.25)))\n",
        "        img = ImageTk.PhotoImage(uploaded)\n",
        "        sign_img.configure(image=img)\n",
        "        sign_img.image=img\n",
        "        label.configure(text='')\n",
        "        show_classify_button(file_path)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "upload=Button(top,text=\"Upload an image\",command=upload_image,padx=10,pady=5)\n",
        "upload.configure(background='#364156', foreground='white',font=('arial',10,'bold'))\n",
        "upload.pack(side=BOTTOM,pady=50)\n",
        "sign_img.pack(side=BOTTOM,expand=True)\n",
        "label.pack(side=BOTTOM,expand=True)\n",
        "heading = Label(top, text=\"CatsVSDogs Classification\",pady=20, font=('arial',20,'bold'))\n",
        "heading.configure(background='#CDCDCD',foreground='#364156')\n",
        "heading.pack()\n",
        "top.mainloop()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VNZ9or8eCUTz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}